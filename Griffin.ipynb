{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('/Users/Palfrey/Downloads/New Folder With Items/Final Project/Train.csv')\n",
    "test = pd.read_csv('/Users/Palfrey/Downloads/New Folder With Items/Final Project/Test.csv')\n",
    "\n",
    "column_rename_dict = {\n",
    "    'fecho_dato': 'date',\n",
    "    'ncodpers': 'customer_code',\n",
    "    'ind_empleado': 'employee_index',\n",
    "    'pais_residencia': 'country_of_residence',\n",
    "    'sexo': 'sex',\n",
    "    'age': 'age',\n",
    "    'fecha_alta': 'holder_start_date',\n",
    "    'ind_nuevo': 'new_customer_index',\n",
    "    'antiguedad': 'seniority',\n",
    "    'indrel': 'primary',\n",
    "    'ult_fec_cli_1t': 'last_date_as_primary',\n",
    "    'indrel_1mes': 'customer_type_at_beginning_of_month',\n",
    "    'tiprel_1mes': 'customer_relation_type_at_beginning_of_month',\n",
    "    'indresi': 'residence_index',\n",
    "    'indext': 'foreigner_index',\n",
    "    'conyuemp': 'spouse_index',\n",
    "    'canal_entrada': 'channel',\n",
    "    'indfall': 'deceased_index',\n",
    "    'tipodom': 'address_type',\n",
    "    'cod_prov': 'province_code',\n",
    "    'nomprov': 'province_name',\n",
    "    'ind_actividad_cliente': 'activity_index',\n",
    "    'renta': 'gross_income',\n",
    "    'segmento': 'segmentation',\n",
    "    'ind_ahor_fin_ult1': 'saving_account',\n",
    "    'ind_aval_fin_ult1': 'guarantees',\n",
    "    'ind_cco_fin_ult1': 'current_accounts',\n",
    "    'ind_cder_fin_ult1': 'derivada_account',\n",
    "    'ind_cno_fin_ult1': 'payroll_account',\n",
    "    'ind_ctju_fin_ult1': 'junior_account',\n",
    "    'ind_ctma_fin_ult1': 'mas_particular_account',\n",
    "    'ind_ctop_fin_ult1': 'particular_account',\n",
    "    'ind_ctpp_fin_ult1': 'particular_plus_account',\n",
    "    'ind_deco_fin_ult1': 'short_term_deposits',\n",
    "    'ind_deme_fin_ult1': 'medium_term_deposits',\n",
    "    'ind_dela_fin_ult1': 'long_term_deposits',\n",
    "    'ind_ecue_fin_ult1': 'e_account',\n",
    "    'ind_fond_fin_ult1': 'funds',\n",
    "    'ind_hip_fin_ult1': 'mortgage',\n",
    "    'ind_plan_fin_ult1': 'pensions',\n",
    "    'ind_pres_fin_ult1': 'loans',\n",
    "    'ind_reca_fin_ult1': 'taxes',\n",
    "    'ind_tjcr_fin_ult1': 'credit_card',\n",
    "    'ind_valo_fin_ult1': 'securities',\n",
    "    'ind_viv_fin_ult1': 'home_account',\n",
    "    'ind_nomina_ult1': 'payroll',\n",
    "    'ind_nom_pens_ult1': 'pensions',\n",
    "    'ind_recibo_ult1': 'direct_debit'\n",
    "    }\n",
    "# Rename columns in both DataFrames\n",
    "train.rename(columns=column_rename_dict, inplace=True)\n",
    "test.rename(columns=column_rename_dict, inplace=True)\n",
    "\n",
    "print(train.columns)\n",
    "print(test.columns)\n",
    "\n",
    "# Get a summary of the data types and non-null counts\n",
    "print(\"Train DataFrame Info:\")\n",
    "print(train.info())\n",
    "'''\n",
    "'''\n",
    "print(\"\\nTest DataFrame Info:\")\n",
    "print(test.info())\n",
    "\n",
    "\"\"\"\n",
    "Data columns (total 48 columns):\n",
    " #   Column                                        Dtype  \n",
    "---  ------                                        -----  \n",
    " 0   fecha_dato                                    object \n",
    " 1   customer_code                                 int64  \n",
    " 2   employee_index                                object \n",
    " 3   country_of_residence                          object \n",
    " 4   sex                                           object \n",
    " 5   age                                           object \n",
    " 6   holder_start_date                             object \n",
    " 7   new_customer_index                            float64\n",
    " 8   seniority                                     object \n",
    " 9   primary                                       float64\n",
    " 10  last_date_as_primary                          object \n",
    " 11  customer_type_at_beginning_of_month           object \n",
    " 12  customer_relation_type_at_beginning_of_month  object \n",
    " 13  residence_index                               object \n",
    " 14  foreigner_index                               object \n",
    " 15  spouse_index                                  object \n",
    " 16  channel                                       object \n",
    " 17  deceased_index                                object \n",
    " 18  address_type                                  float64\n",
    " 19  province_code                                 float64\n",
    " 20  province_name                                 object \n",
    " 21  activity_index                                float64\n",
    " 22  gross_income                                  float64\n",
    " 23  segmentation                                  object \n",
    " 24  saving_account                                int64  \n",
    " 25  guarantees                                    int64  \n",
    " 26  current_accounts                              int64  \n",
    " 27  derivada_account                              int64  \n",
    " 28  payroll_account                               int64  \n",
    " 29  junior_account                                int64  \n",
    " 30  mas_particular_account                        int64  \n",
    " 31  particular_account                            int64  \n",
    " 32  particular_plus_account                       int64  \n",
    " 33  short_term_deposits                           int64  \n",
    " 34  medium_term_deposits                          int64  \n",
    " 35  long_term_deposits                            int64  \n",
    " 36  e_account                                     int64  \n",
    " 37  funds                                         int64  \n",
    " 38  mortgage                                      int64  \n",
    " 39  pensions                                      int64  \n",
    " 40  loans                                         int64  \n",
    " 41  taxes                                         int64  \n",
    " 42  credit_card                                   int64  \n",
    " 43  securities                                    int64  \n",
    " 44  home_account                                  int64  \n",
    " 45  payroll                                       float64\n",
    " 46  pensions                                      float64\n",
    " 47  direct_debit                                  int64  \n",
    "dtypes: float64(8), int64(23), object(17)\n",
    "memory usage: 4.9+ GB\n",
    "None\n",
    "\n",
    "Test DataFrame Info:\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 929615 entries, 0 to 929614\n",
    "Data columns (total 24 columns):\n",
    " #   Column                                        Non-Null Count   Dtype  \n",
    "---  ------                                        --------------   -----  \n",
    " 0   fecha_dato                                    929615 non-null  object \n",
    " 1   customer_code                                 929615 non-null  int64  \n",
    " 2   employee_index                                929615 non-null  object \n",
    " 3   country_of_residence                          929615 non-null  object \n",
    " 4   sex                                           929610 non-null  object \n",
    " 5   age                                           929615 non-null  int64  \n",
    " 6   holder_start_date                             929615 non-null  object \n",
    " 7   new_customer_index                            929615 non-null  int64  \n",
    " 8   seniority                                     929615 non-null  int64  \n",
    " 9   primary                                       929615 non-null  int64  \n",
    " 10  last_date_as_primary                          1683 non-null    object \n",
    " 11  customer_type_at_beginning_of_month           929592 non-null  float64\n",
    " 12  customer_relation_type_at_beginning_of_month  929592 non-null  object \n",
    " 13  residence_index                               929615 non-null  object \n",
    " 14  foreigner_index                               929615 non-null  object \n",
    " 15  spouse_index                                  104 non-null     object \n",
    " 16  channel                                       927534 non-null  object \n",
    " 17  deceased_index                                929615 non-null  object \n",
    " 18  address_type                                  929615 non-null  int64  \n",
    " 19  province_code                                 925619 non-null  float64\n",
    " 20  province_name                                 925619 non-null  object \n",
    " 21  activity_index                                929615 non-null  int64  \n",
    " 22  gross_income                                  929615 non-null  object \n",
    " 23  segmentation                                  927367 non-null  object \n",
    "\n",
    "dtypes: float64(2), int64(8), object(14)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Check for missing values in the train DataFrame\n",
    "print(\"Missing Values in Train DataFrame:\")\n",
    "print(train.isnull().sum())\n",
    "\n",
    "# Check for missing values in the test DataFrame\n",
    "print(\"\\nMissing Values in Test DataFrame:\")\n",
    "print(test.isnull().sum())\n",
    "\n",
    "'''\n",
    "Missing Values in Train DataFrame:\n",
    "fecha_dato                                             0\n",
    "customer_code                                          0\n",
    "employee_index                                     27734\n",
    "country_of_residence                               27734\n",
    "sex                                                27804\n",
    "age                                                    0\n",
    "holder_start_date                                  27734\n",
    "new_customer_index                                 27734\n",
    "seniority                                              0\n",
    "primary                                            27734\n",
    "last_date_as_primary                            13622516\n",
    "customer_type_at_beginning_of_month               149781\n",
    "customer_relation_type_at_beginning_of_month      149781\n",
    "residence_index                                    27734\n",
    "foreigner_index                                    27734\n",
    "spouse_index                                    13645501\n",
    "channel                                           186126\n",
    "deceased_index                                     27734\n",
    "address_type                                       27735\n",
    "province_code                                      93591\n",
    "province_name                                      93591\n",
    "activity_index                                     27734\n",
    "gross_income                                     2794375\n",
    "segmentation                                      189368\n",
    "saving_account                                         0\n",
    "guarantees                                             0\n",
    "current_accounts                                       0\n",
    "derivada_account                                       0\n",
    "payroll_account                                        0\n",
    "junior_account                                         0\n",
    "mas_particular_account                                 0\n",
    "particular_account                                     0\n",
    "particular_plus_account                                0\n",
    "short_term_deposits                                    0\n",
    "medium_term_deposits                                   0\n",
    "long_term_deposits                                     0\n",
    "e_account                                              0\n",
    "funds                                                  0\n",
    "mortgage                                               0\n",
    "pensions                                               0\n",
    "loans                                                  0\n",
    "taxes                                                  0\n",
    "credit_card                                            0\n",
    "securities                                             0\n",
    "home_account                                           0\n",
    "payroll                                            16063\n",
    "pensions                                           16063\n",
    "direct_debit                                           0\n",
    "dtype: int64\n",
    "\n",
    "Missing Values in Test DataFrame:\n",
    "fecha_dato                                           0\n",
    "customer_code                                        0\n",
    "employee_index                                       0\n",
    "country_of_residence                                 0\n",
    "sex                                                  5\n",
    "age                                                  0\n",
    "holder_start_date                                    0\n",
    "new_customer_index                                   0\n",
    "seniority                                            0\n",
    "primary                                              0\n",
    "last_date_as_primary                            927932\n",
    "customer_type_at_beginning_of_month                 23\n",
    "customer_relation_type_at_beginning_of_month        23\n",
    "residence_index                                      0\n",
    "foreigner_index                                      0\n",
    "spouse_index                                    929511\n",
    "channel                                           2081\n",
    "deceased_index                                       0\n",
    "address_type                                         0\n",
    "province_code                                     3996\n",
    "province_name                                     3996\n",
    "activity_index                                       0\n",
    "gross_income                                         0\n",
    "segmentation                                      2248\n",
    "dtype: int64\n",
    "\n",
    "'''\n",
    "# Convert all columns to numeric, coercing errors to NaN\n",
    "train = train.apply(pd.to_numeric, errors='coerce')\n",
    "# Z-score method\n",
    "z_scores = stats.zscore(train.select_dtypes(include=['float64', 'int64']))\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "outliers = (abs_z_scores > 3).all(axis=1)\n",
    "print(\"Outliers based on Z-score:\", outliers.sum())\n",
    "\n",
    "# IQR method\n",
    "Q1 = train.quantile(0.25)\n",
    "Q3 = train.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = ((train < (Q1 - 1.5 * IQR)) | (train > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "print(\"Outliers based on IQR:\", outliers.sum())\n",
    "\n",
    "'''\n",
    "Outliers based on Z-score: 0\n",
    "Outliers based on IQR: 6101444\n",
    "\n",
    "'''\n",
    "\n",
    "# Select only numeric columns from the train DataFrame\n",
    "numeric_train = train.select_dtypes(include=['number'])\n",
    "\n",
    "# Select only numeric columns from the test DataFrame\n",
    "numeric_test = test.select_dtypes(include=['number'])\n",
    "\n",
    "# Calculate skewness for each numeric column in the train DataFrame\n",
    "train_skewness = numeric_train.skew()\n",
    "\n",
    "# Calculate skewness for each numeric column in the test DataFrame\n",
    "test_skewness = numeric_test.skew()\n",
    "\n",
    "# Print skewness values\n",
    "print(\"Skewness in Train DataFrame:\")\n",
    "print(train_skewness)\n",
    "\n",
    "print(\"\\nSkewness in Test DataFrame:\")\n",
    "print(test_skewness)\n",
    "\n",
    "'''\n",
    "Skewness in Train DataFrame:\n",
    "fecha_dato                                             NaN\n",
    "customer_code                                    -0.293747\n",
    "employee_index                                         NaN\n",
    "country_of_residence                                   NaN\n",
    "sex                                                    NaN\n",
    "age                                               0.804207\n",
    "holder_start_date                                      NaN\n",
    "new_customer_index                                3.721909\n",
    "seniority                                      -597.255999\n",
    "primary                                          23.373776\n",
    "last_date_as_primary                                   NaN\n",
    "customer_type_at_beginning_of_month              51.792897\n",
    "customer_relation_type_at_beginning_of_month           NaN\n",
    "residence_index                                        NaN\n",
    "foreigner_index                                        NaN\n",
    "spouse_index                                           NaN\n",
    "channel                                           0.082240\n",
    "deceased_index                                         NaN\n",
    "address_type                                      0.000000\n",
    "province_code                                    -0.124528\n",
    "province_name                                          NaN\n",
    "activity_index                                    0.169362\n",
    "gross_income                                     53.257206\n",
    "segmentation                                           NaN\n",
    "saving_account                                   98.858543\n",
    "guarantees                                      207.809278\n",
    "current_accounts                                 -0.654378\n",
    "derivada_account                                 50.354373\n",
    "payroll_account                                   3.074725\n",
    "junior_account                                   10.127175\n",
    "mas_particular_account                            9.991027\n",
    "particular_account                                2.213494\n",
    "particular_plus_account                           4.487410\n",
    "short_term_deposits                              23.647367\n",
    "medium_term_deposits                             24.475570\n",
    "long_term_deposits                                4.507626\n",
    "e_account                                         3.029149\n",
    "funds                                             7.149396\n",
    "mortgage                                         12.918353\n",
    "pensions                                         10.298012\n",
    "loans                                            19.432099\n",
    "taxes                                             4.011220\n",
    "credit_card                                       4.424333\n",
    "securities                                        6.006428\n",
    "home_account                                     16.028044\n",
    "payroll                                           3.915520\n",
    "pensions                                          3.726945\n",
    "direct_debit                                      2.228070\n",
    "dtype: float64\n",
    "\n",
    "Skewness in Test DataFrame:\n",
    "customer_code                           -0.327419\n",
    "age                                      0.830373\n",
    "new_customer_index                       5.739031\n",
    "seniority                             -555.491690\n",
    "primary                                 23.438419\n",
    "customer_type_at_beginning_of_month    185.543646\n",
    "address_type                             0.000000\n",
    "province_code                           -0.124568\n",
    "activity_index                           0.302309\n",
    "dtype: float64\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "# Assuming train and test DataFrames are already loaded\n",
    "\n",
    "def get_mixed_type_columns(df):\n",
    "    # Apply a function to get the type of each element\n",
    "    type_df = df.applymap(type)\n",
    "    \n",
    "    # Identify columns with more than one unique type\n",
    "    mixed_type_columns = [col for col in type_df.columns if len(type_df[col].unique()) > 1]\n",
    "    \n",
    "    return mixed_type_columns\n",
    "\n",
    "# Get columns with mixed data types in the train DataFrame\n",
    "mixed_type_columns_train = get_mixed_type_columns(train)\n",
    "\n",
    "# Get columns with mixed data types in the test DataFrame\n",
    "mixed_type_columns_test = get_mixed_type_columns(test)\n",
    "\n",
    "# Print the columns with mixed data types\n",
    "print(\"Columns with mixed data types in Train DataFrame:\")\n",
    "print(mixed_type_columns_train)\n",
    "\n",
    "print(\"\\nColumns with mixed data types in Test DataFrame:\")\n",
    "print(mixed_type_columns_test)\n",
    "\n",
    "DtypeWarning: Columns (5,8,11,15) have mixed types\n",
    "This includes: age, seniority, customer_type_at_beginning_of_month, and foreigner index\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Now let's look into some of the best ways to 'clean' the data\n",
    "\n",
    "# First, let's analyze the mean/median/mode/Model based approach to handle NA value, and when to use each one \n",
    "\n",
    "# For 'Mean Inputation Approach', let's call it, we can replace the NA value with the mean of the column. This however, is only suitable for columns with strictly numerical values, and low skewness, or close to a normal distribution. \n",
    "# BASICALLY, we want to tailor this approach to columns with a HIGH number of missing values AND LOW skewness. \n",
    "'''\n",
    "From above list of columns with missing values, we can see that the columns with missing values are:\n",
    "\n",
    "for train data set:\n",
    "\n",
    "employee_index                                     27734\n",
    "country_of_residence                               27734\n",
    "sex                                                27804\n",
    "holder_start_date                                  27734\n",
    "new_customer_index                                 27734\n",
    "primary                                            27734\n",
    "last_date_as_primary                            13622516\n",
    "customer_type_at_beginning_of_month               149781\n",
    "customer_relation_type_at_beginning_of_month      149781\n",
    "residence_index                                    27734\n",
    "foreigner_index                                    27734\n",
    "spouse_index                                    13645501\n",
    "channel                                           186126\n",
    "deceased_index                                     27734\n",
    "address_type                                       27735\n",
    "province_code                                      93591\n",
    "province_name                                      93591\n",
    "activity_index                                     27734\n",
    "gross_income                                     2794375\n",
    "segmentation                                      189368\n",
    "payroll                                            16063\n",
    "pensions                                           16063\n",
    "\n",
    "for test data set:\n",
    "last_date_as_primary                            927932\n",
    "customer_type_at_beginning_of_month                 23\n",
    "customer_relation_type_at_beginning_of_month        23\n",
    "spouse_index                                    929511\n",
    "channel                                           2081\n",
    "province_code                                     3996\n",
    "province_name                                     3996\n",
    "segmentation                                      2248\n",
    "\n",
    "\n",
    "From the above list of skewness (let's consider high skewness to be out of the range of -1 to 1), we can see that the columns with low skewness are: \n",
    "customer_code                                    -0.293747\n",
    "age                                               0.804207\n",
    "channel                                           0.082240\n",
    "address_type                                      0.000000\n",
    "province_code                                    -0.124528\n",
    "activity_index                                    0.169362\n",
    "current_accounts                                 -0.654378\n",
    "\n",
    "customer_code                           -0.327419\n",
    "address_type                             0.000000\n",
    "province_code                           -0.124568\n",
    "activity_index                           0.302309\n",
    "age                                      0.830373\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Channel and address_type are the only columns with low skewness and high number of missing values. We can use the mean inputation approach for these columns.\n",
    "\n",
    "# Calculate the mean value for 'address_type' and 'channel'\n",
    "mean_address_type = train['address_type'].mean()\n",
    "mean_channel = train['channel'].mean()\n",
    "\n",
    "# Replace missing values in 'address_type' and 'channel' with their mean values\n",
    "train['address_type'].fillna(mean_address_type, inplace=True)\n",
    "train['channel'].fillna(mean_channel, inplace=True)\n",
    "\n",
    "# Print to verify the changes\n",
    "print(train['address_type'].isnull().sum())  # Should print 0\n",
    "print(train['channel'].isnull().sum())       # Should print 0\n",
    "\n",
    "\n",
    "# Calculate the mean value for 'address_type' and 'channel'\n",
    "mean_address_type = train['address_type'].mean()\n",
    "mean_channel = train['channel'].mean()\n",
    "\n",
    "# Print the mean values for each column\n",
    "print(mean_address_type)\n",
    "print(mean_channel)\n",
    "'''\n",
    "1.0\n",
    "9.878\n",
    "'''\n",
    "\n",
    "# Replace missing values in 'address_type' and 'channel' with their mean values using loc\n",
    "train.loc[:, 'address_type'] = train['address_type'].fillna(mean_address_type)\n",
    "train.loc[:, 'channel'] = train['channel'].fillna(mean_channel)\n",
    "\n",
    "\n",
    "# Print to verify the changes\n",
    "print(train['address_type'].isnull().sum())  # Should print 0\n",
    "print(train['channel'].isnull().sum())       # Should print 0\n",
    "\n",
    "\n",
    "# For 'Median Inputation Approach', we can replace the NA value with the median of the column. This is only suitable for columns with strictly numerical values, but since the median is less sensitive to outliers, it is more suitable for columns with high skewness.\n",
    "# BASICALLY, we want to tailor this approach to columns with a HIGH number of missing values AND relatively high skewness.\n",
    "'''\n",
    "From above list of columns with missing values, we can see that the columns with missing values are:\n",
    "\n",
    "for train data set:\n",
    "\n",
    "employee_index                                     27734\n",
    "country_of_residence                               27734\n",
    "sex                                                27804\n",
    "holder_start_date                                  27734\n",
    "new_customer_index                                 27734\n",
    "primary                                            27734\n",
    "last_date_as_primary                            13622516\n",
    "customer_type_at_beginning_of_month               149781\n",
    "customer_relation_type_at_beginning_of_month      149781\n",
    "residence_index                                    27734\n",
    "foreigner_index                                    27734\n",
    "spouse_index                                    13645501\n",
    "channel                                           186126\n",
    "deceased_index                                     27734\n",
    "address_type                                       27735\n",
    "province_code                                      93591\n",
    "province_name                                      93591\n",
    "activity_index                                     27734\n",
    "gross_income                                     2794375\n",
    "segmentation                                      189368\n",
    "payroll                                            16063\n",
    "pensions                                           16063\n",
    "\n",
    "for test data set:\n",
    "last_date_as_primary                            927932\n",
    "customer_type_at_beginning_of_month                 23\n",
    "customer_relation_type_at_beginning_of_month        23\n",
    "spouse_index                                    929511\n",
    "channel                                           2081\n",
    "province_code                                     3996\n",
    "province_name                                     3996\n",
    "segmentation                                      2248\n",
    "\n",
    "\n",
    "From the above list of skewness (let's consider high skewness to be out of the range of -1 to 1), we can see that the columns with high skewness are:\n",
    "\n",
    "for train data set:\n",
    "seniority                                      -597.255999\n",
    "saving_account                                   98.858543\n",
    "guarantees                                      207.809278\n",
    "customer_type_at_beginning_of_month              51.792897\n",
    "derivada_account                                 50.354373\n",
    "payroll_account                                   3.074725\n",
    "junior_account                                   10.127175\n",
    "mas_particular_account                            9.991027\n",
    "particular_account                                2.213494\n",
    "particular_plus_account                           4.487410\n",
    "short_term_deposits                              23.647367\n",
    "medium_term_deposits                             24.475570\n",
    "long_term_deposits                                4.507626\n",
    "e_account                                         3.029149\n",
    "funds                                             7.149396\n",
    "mortgage                                         12.918353\n",
    "pensions                                         10.298012\n",
    "loans                                            19.432099\n",
    "taxes                                             4.011220\n",
    "credit_card                                       4.424333\n",
    "securities                                        6.006428\n",
    "home_account                                     16.028044\n",
    "payroll                                           3.915520\n",
    "pensions                                          3.726945\n",
    "direct_debit                                      2.228070\n",
    "\n",
    "for test data set:\n",
    "new_customer_index                       5.739031\n",
    "seniority                             -555.491690\n",
    "primary                                 23.438419\n",
    "customer_type_at_beginning_of_month    185.543646\n",
    "\n",
    "'''\n",
    "# Seniority, saving_account, guarantees, customer_type_at_beginning_of_month, derivada_account, payroll_account, junior_account, mas_particular_account, particular_account, particular_plus_account, short_term_deposits, medium_term_deposits, long_term_deposits, e_account, funds, mortgage, pensions, loans, taxes, credit_card, securities, home_account, payroll, pensions, and direct_debit are the only columns with high skewness and high number of missing values. We can use the median inputation approach for these columns.\n",
    "\n",
    "# List of columns to perform median imputation\n",
    "# List of columns to perform median imputation\n",
    "columns_to_impute = [\n",
    "    'seniority', 'saving_account', 'guarantees', 'customer_type_at_beginning_of_month', \n",
    "    'derivada_account', 'payroll_account', 'junior_account', 'mas_particular_account', \n",
    "    'particular_account', 'particular_plus_account', 'short_term_deposits', \n",
    "    'medium_term_deposits', 'long_term_deposits', 'e_account', 'funds', 'mortgage', \n",
    "    'pensions', 'loans', 'taxes', 'credit_card', 'securities', 'home_account', \n",
    "    'payroll', 'direct_debit'\n",
    "]\n",
    "\n",
    "# Check for duplicate columns in the DataFrame\n",
    "duplicate_columns = train.columns[train.columns.duplicated()].tolist()\n",
    "if duplicate_columns:\n",
    "    print(f\"Duplicate columns found: {duplicate_columns}\")\n",
    "else:\n",
    "    print(\"No duplicate columns found.\")\n",
    "\n",
    "# Replace missing values with the median for each specified column\n",
    "for column in columns_to_impute:\n",
    "    if column in train.columns:\n",
    "        try:\n",
    "            median_value = train[column].median()\n",
    "            print(f\"Filling missing values in column: {column} with median value: {median_value}\")\n",
    "            train.loc[:, column] = train[column].fillna(median_value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing column {column}: {e}\")\n",
    "    else:\n",
    "        print(f\"Column {column} not found in DataFrame.\")\n",
    "\n",
    "# Print to verify the changes\n",
    "for column in columns_to_impute:\n",
    "    if column in train.columns:\n",
    "        print(f\"{column} missing values: {train[column].isnull().sum()}\")\n",
    "\n",
    "\n",
    "# For 'Mode Inputation Approach', we can replace the NA value with the mode of the column, that is the most frequent observed value. This is suitable for columns with categorical values or discrete numerical data\n",
    "# Let's start by printing out the columns with categorical values\n",
    "# Select columns with categorical variables (type 'object')\n",
    "# List of columns that should be categorical\n",
    "categorical_columns = [\n",
    "    'employee_index', 'country_of_residence', 'sex', 'new_customer_index', 'primary',\n",
    "    'customer_type_at_beginning_of_month', 'customer_relation_type_at_beginning_of_month',\n",
    "    'residence_index', 'foreigner_index', 'spouse_index', 'channel', 'deceased_index',\n",
    "    'address_type', 'province_code', 'province_name', 'activity_index', 'segmentation'\n",
    "]\n",
    "\n",
    "# Convert these columns to categorical type\n",
    "for column in categorical_columns:\n",
    "    if column in train.columns:\n",
    "        train[column] = train[column].astype('category')\n",
    "    if column in test.columns:\n",
    "        test[column] = test[column].astype('category')\n",
    "\n",
    "# Perform mode imputation for categorical columns\n",
    "for column in categorical_columns:\n",
    "    if column in train.columns:\n",
    "        if not train[column].mode().empty:\n",
    "            mode_value = train[column].mode()[0]\n",
    "            train.loc[:, column] = train[column].fillna(mode_value)\n",
    "        else:\n",
    "            print(f\"Column {column} in train DataFrame has no mode (all values might be NaN).\")\n",
    "    if column in test.columns:\n",
    "        if not test[column].mode().empty:\n",
    "            mode_value = test[column].mode()[0]\n",
    "            test.loc[:, column] = test[column].fillna(mode_value)\n",
    "        else:\n",
    "            print(f\"Column {column} in test DataFrame has no mode (all values might be NaN).\")\n",
    "\n",
    "# Print to verify the changes\n",
    "print(\"Mode imputation completed for categorical columns in Train DataFrame:\")\n",
    "for column in categorical_columns:\n",
    "    if column in train.columns:\n",
    "        print(f\"{column} missing values: {train[column].isnull().sum()}\")\n",
    "\n",
    "print(\"\\nMode imputation completed for categorical columns in Test DataFrame:\")\n",
    "for column in categorical_columns:\n",
    "    if column in test.columns:\n",
    "        print(f\"{column} missing values: {test[column].isnull().sum()}\")\n",
    "\n",
    "''' \n",
    "What this extended code tells us is that the categorical columns listed above either strictly contain nan values (and therefore have no mode value to adopt), or have been successfully imputed with the mode value.\n",
    "'''\n",
    "\n",
    "# For 'Model Based Approach', involves using predictive models to estimate and impute missing values based on other available features. This can involve regression models, classification models, or more complex algorithms. \n",
    "\n",
    "# Import needed classes and libraries\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# List of columns to impute\n",
    "columns_to_impute = [\n",
    "    'seniority', 'saving_account', 'guarantees', 'customer_type_at_beginning_of_month', \n",
    "    'derivada_account', 'payroll_account', 'junior_account', 'mas_particular_account', \n",
    "    'particular_account', 'particular_plus_account', 'short_term_deposits', \n",
    "    'medium_term_deposits', 'long_term_deposits', 'e_account', 'funds', 'mortgage', \n",
    "    'pensions', 'loans', 'taxes', 'credit_card', 'securities', 'home_account', \n",
    "    'payroll', 'direct_debit'\n",
    "]\n",
    "\n",
    "# Combine train and test data for imputation\n",
    "combined = pd.concat([train[columns_to_impute], test[columns_to_impute]], axis=0)\n",
    "\n",
    "# Initialize the IterativeImputer\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "# Fit the imputer on the combined data and transform it\n",
    "imputed_data = imputer.fit_transform(combined)\n",
    "\n",
    "# Split the imputed data back into train and test sets\n",
    "train_imputed = imputed_data[:len(train)]\n",
    "test_imputed = imputed_data[len(train):]\n",
    "\n",
    "# Replace the original columns with the imputed data\n",
    "train[columns_to_impute] = train_imputed\n",
    "test[columns_to_impute] = test_imputed\n",
    "\n",
    "# Print to verify the changes\n",
    "print(\"Model-based imputation completed for columns in Train DataFrame:\")\n",
    "for column in columns_to_impute:\n",
    "    print(f\"{column} missing values: {train[column].isnull().sum()}\")\n",
    "\n",
    "print(\"\\nModel-based imputation completed for columns in Test DataFrame:\")\n",
    "for column in columns_to_impute:\n",
    "    print(f\"{column} missing values: {test[column].isnull().sum()}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
